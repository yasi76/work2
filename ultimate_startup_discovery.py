#!/usr/bin/env python3

# =============================================================================
# PATCH: Fix for status_code TypeError
# =============================================================================

def safe_int_comparison(value, default=0):
    """Safely convert value to int for comparison, handling None and invalid types"""
    if value is None:
        return default
    try:
        return int(value)
    except (ValueError, TypeError):
        return default

def safe_float_comparison(value, default=0.0):
    """Safely convert value to float for comparison, handling None and invalid types"""
    if value is None:
        return default
    try:
        return float(value)
    except (ValueError, TypeError):
        return default

def apply_smart_sorting_safe(results):
    """
    Safe version of smart sorting that handles None status_code values
    """
    def safe_sort_key(result):
        # Safely get and convert status_code
        status_code = safe_int_comparison(result.get('status_code'), 0)
        
        # Calculate status priority with safe comparisons
        if 200 <= safe_int_comparison(status_code) < 300:
            status_priority = 10  # Success responses
        elif 300 <= safe_int_comparison(status_code) < 400:
            status_priority = 8   # Redirects
        elif status_code == 0:
            status_priority = 5   # Unknown status
        elif 400 <= safe_int_comparison(status_code) < 500:
            status_priority = 2   # Client errors
        elif 500 <= safe_int_comparison(status_code) < 600:
            status_priority = 1   # Server errors
        else:
            status_priority = 3   # Other status codes
        
        # Safely get other criteria
        confidence = safe_int_comparison(result.get('confidence'), 0)
        health_score = safe_float_comparison(result.get('health_relevance_score'), 0.0)
        
        # Method priority
        method_priority = {
            'User Verified': 100, 'Hardcoded': 95, 'Manual Curation': 90,
            'Conference': 85, 'Google Search': 80, 'Enhanced Discovery': 75,
            'LinkedIn': 70, 'Bing Search': 65, 'News Aggregator': 60,
            'Domain Generation': 50, 'Generated': 40, 'Unknown': 10
        }
        
        method = result.get('method', 'Unknown')
        method_score = method_priority.get(method, 10)
        
        # Calculate composite score
        composite_score = (
            status_priority * 1000 + confidence * 100 + method_score * 10 + health_score
        )
        
        return composite_score
    
    try:
        sorted_results = sorted(results, key=safe_sort_key, reverse=True)
        print(f"‚úÖ Successfully sorted {len(sorted_results)} results")
        return sorted_results
    except Exception as e:
        print(f"‚ö†Ô∏è Error in smart sorting: {e}")
        return results

def fix_status_code_data(results):
    """Fix status_code and other numeric fields in results"""
    fixed_results = []
    for result in results:
        fixed_result = result.copy()
        fixed_result['status_code'] = safe_int_comparison(result.get('status_code'), 0)
        fixed_result['confidence'] = safe_int_comparison(result.get('confidence'), 0)
        fixed_result['health_relevance_score'] = safe_float_comparison(
            result.get('health_relevance_score'), 0.0
        )
        fixed_results.append(fixed_result)
    return fixed_results

# =============================================================================
# END PATCH
# =============================================================================


"""
ULTIMATE STARTUP DISCOVERY SYSTEM
Combines multiple discovery methods to find digital health startups
Uses only free tools and prioritizes real startup websites
"""

import json
import csv
import time
from datetime import datetime
from typing import List, Dict, Set
import sys
import os

# Import discovery methods
try:
    from enhanced_startup_discovery import EnhancedStartupDiscovery
    from google_search_scraper import GoogleSearchStartupFinder
except ImportError as e:
    print(f"‚ö†Ô∏è Import error: {e}")
    print("Make sure all discovery modules are in the same directory")
    sys.exit(1)

class UltimateStartupDiscovery:
    def __init__(self):
        self.all_discovered_urls = set()
        self.final_results = []
        
    def get_user_hardcoded_urls(self) -> List[Dict]:
        """User's verified hardcoded URLs - Always included with highest priority"""
        print("üîç Loading user's verified hardcoded URLs...")
        
        user_urls = [
            'https://www.acalta.de',
            'https://www.actimi.com',
            'https://www.emmora.de',
            'https://www.alfa-ai.com',
            'https://www.apheris.com',
            'https://www.aporize.com/',
            'https://www.arztlena.com/',
            'https://shop.getnutrio.com/',
            'https://www.auta.health/',
            'https://visioncheckout.com/',
            'https://www.avayl.tech/',
            'https://www.avimedical.com/avi-impact',
            'https://de.becureglobal.com/',
            'https://bellehealth.co/de/',
            'https://www.biotx.ai/',
            'https://www.brainjo.de/',
            'https://brea.app/',
            'https://breathment.com/',
            'https://de.caona.eu/',
            'https://www.careanimations.de/',
            'https://sfs-healthcare.com',
            'https://www.climedo.de/',
            'https://www.cliniserve.de/',
            'https://cogthera.de/#erfahren',
            'https://www.comuny.de/',
            'https://curecurve.de/elina-app/',
            'https://www.cynteract.com/de/rehabilitation',
            'https://www.healthmeapp.de/de/',
            'https://deepeye.ai/',
            'https://www.deepmentation.ai/',
            'https://denton-systems.de/',
            'https://www.derma2go.com/',
            'https://www.dianovi.com/',
            'http://dopavision.com/',
            'https://www.dpv-analytics.com/',
            'http://www.ecovery.de/',
            'https://elixionmedical.com/',
            'https://www.empident.de/',
            'https://eye2you.ai/',
            'https://www.fitwhit.de',
            'https://www.floy.com/',
            'https://fyzo.de/assistant/',
            'https://www.gesund.de/app',
            'https://www.glaice.de/',
            'https://gleea.de/',
            'https://www.guidecare.de/',
            'https://www.apodienste.com/',
            'https://www.help-app.de/',
            'https://www.heynanny.com/',
            'https://incontalert.de/',
            'https://home.informme.info/',
            'https://www.kranushealth.com/de/therapien/haeufiger-harndrang',
            'https://www.kranushealth.com/de/therapien/inkontinenz'
        ]
        
        results = []
        for url in user_urls:
            results.append({
                'url': url,
                'source': 'User Verified',
                'confidence': 10,
                'category': 'Verified Health Tech',
                'country': 'Germany/Europe',
                'method': 'Hardcoded'
            })
            self.all_discovered_urls.add(url)
            
        print(f"‚úÖ Loaded {len(results)} verified user URLs")
        return results

    def run_enhanced_discovery(self) -> List[Dict]:
        """Run the enhanced startup discovery method"""
        print("\nüöÄ Running Enhanced Startup Discovery...")
        print("-" * 50)
        
        try:
            discoverer = EnhancedStartupDiscovery()
            results = discoverer.discover_all_startups()
            
            enhanced_results = []
            for url_data in results['urls']:
                if url_data['url'] not in self.all_discovered_urls:
                    self.all_discovered_urls.add(url_data['url'])
                    url_data['method'] = 'Enhanced Discovery'
                    enhanced_results.append(url_data)
            
            print(f"‚úÖ Enhanced discovery found {len(enhanced_results)} new URLs")
            return enhanced_results
            
        except Exception as e:
            print(f"‚ö†Ô∏è Enhanced discovery error: {str(e)}")
            return []

    def run_google_search_discovery(self) -> List[Dict]:
        """Run the Google search-based discovery method"""
        print("\nüîç Running Google Search Discovery...")
        print("-" * 50)
        
        try:
            finder = GoogleSearchStartupFinder()
            results = finder.discover_all_startups()
            
            google_results = []
            for url_data in results['urls']:
                if url_data['url'] not in self.all_discovered_urls:
                    self.all_discovered_urls.add(url_data['url'])
                    url_data['method'] = 'Google Search'
                    google_results.append(url_data)
            
            print(f"‚úÖ Google search found {len(google_results)} new URLs")
            return google_results
            
        except Exception as e:
            print(f"‚ö†Ô∏è Google search discovery error: {str(e)}")
            return []

    def add_curated_startup_urls(self) -> List[Dict]:
        """Add manually curated startup URLs from known sources"""
        print("\nüìã Adding curated startup URLs...")
        print("-" * 50)
        
        # Additional curated startups from various sources
        curated_startups = [
            # German Digital Health Leaders
            'https://www.ada.com',
            'https://www.doctolib.de',
            'https://www.kaia-health.com',
            'https://www.teleclinic.com',
            'https://www.zavamed.com',
            'https://www.medwing.com',
            'https://www.felmo.de',
            'https://www.viomedo.de',
            'https://www.caresyntax.com',
            'https://www.merantix.com',
            'https://www.contextflow.com',
            'https://www.heartkinetics.com',
            'https://www.samedi.de',
            'https://www.medigene.com',
            'https://www.smartpatient.eu',
            
            # European Digital Health
            'https://www.doctolib.fr',
            'https://www.livi.co.uk',
            'https://www.babylon.com',
            'https://www.echo.co.uk',
            'https://www.accurx.com',
            'https://www.zava.com',
            'https://www.medgate.ch',
            'https://www.kry.se',
            'https://www.medadom.com',
            'https://www.qare.fr',
            'https://www.1177.se',
            'https://www.netdoktor.dk',
            'https://www.opensafely.org',
            
            # AI & Analytics
            'https://www.owkin.com',
            'https://www.benevolent.ai',
            'https://www.exscientia.ai',
            'https://www.healx.io',
            'https://www.deepmind.com/about/health',
            'https://www.insilico.com',
            
            # MedTech & Devices
            'https://www.siemens-healthineers.com',
            'https://www.philips.com/healthcare',
            'https://www.getinge.com',
            'https://www.elekta.com',
            'https://www.fresenius.com',
            'https://www.braun.com',
            
            # Pharma & Biotech
            'https://www.bayer.com',
            'https://www.boehringer-ingelheim.com',
            'https://www.merckgroup.com',
            'https://www.qiagen.com',
            'https://www.roche.com',
            'https://www.novartis.com',
            'https://www.sanofi.com',
            'https://www.gsk.com',
            'https://www.astrazeneca.com',
            
            # Emerging Startups
            'https://www.mindmaze.com',
            'https://www.sophia-genetics.com',
            'https://www.iqvia.com',
            'https://www.veracyte.com',
            'https://www.tempus.com',
            'https://www.flatiron.com',
            'https://www.paige.ai',
            'https://www.path.ai',
            'https://www.viz.ai',
            'https://www.arterys.com'
        ]
        
        results = []
        for url in curated_startups:
            if url not in self.all_discovered_urls:
                self.all_discovered_urls.add(url)
                results.append({
                    'url': url,
                    'source': 'Curated List',
                    'confidence': 8,
                    'category': 'Curated Health Tech',
                    'country': 'Europe/International',
                    'method': 'Manual Curation'
                })
        
        print(f"‚úÖ Added {len(results)} curated startup URLs")
        return results

    def consolidate_and_rank_results(self, all_results: List[Dict]) -> List[Dict]:
        """Consolidate results and rank by confidence and relevance"""
        print("\nüîÑ Consolidating and ranking results...")
        print("-" * 50)
        
        # Remove any remaining duplicates
        unique_results = []
        seen_urls = set()
        
        # Sort by confidence (highest first), then by method priority
        method_priority = {
            'Hardcoded': 5,
            'Manual Curation': 4,
            'Google Search': 3,
            'Enhanced Discovery': 2,
            'Generated': 1
        }
        
        sorted_results = sorted(all_results, key=lambda x: (
            x['confidence'], 
            method_priority.get(x.get('method', 'Unknown'), 0)
        ), reverse=True)
        
        for result in sorted_results:
            url = result['url']
            if url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        print(f"‚úÖ Consolidated to {len(unique_results)} unique URLs")
        return unique_results

    def analyze_discovery_results(self, results: List[Dict]) -> Dict:
        """Analyze the discovery results and provide statistics"""
        print("\nüìä Analyzing discovery results...")
        print("-" * 50)
        
        # Count by method
        method_counts = {}
        confidence_distribution = {}
        category_counts = {}
        country_counts = {}
        
        for result in results:
            method = result.get('method', 'Unknown')
            confidence = result.get('confidence', 0)
            category = result.get('category', 'Unknown')
            country = result.get('country', 'Unknown')
            
            method_counts[method] = method_counts.get(method, 0) + 1
            confidence_distribution[confidence] = confidence_distribution.get(confidence, 0) + 1
            category_counts[category] = category_counts.get(category, 0) + 1
            country_counts[country] = country_counts.get(country, 0) + 1
        
        # Calculate quality metrics
        high_confidence = len([r for r in results if r.get('confidence', 0) >= 8])
        medium_confidence = len([r for r in results if 5 <= r.get('confidence', 0) < 8])
        low_confidence = len([r for r in results if r.get('confidence', 0) < 5])
        
        analysis = {
            'total_urls': len(results),
            'method_counts': method_counts,
            'confidence_distribution': confidence_distribution,
            'category_counts': category_counts,
            'country_counts': country_counts,
            'quality_metrics': {
                'high_confidence': high_confidence,
                'medium_confidence': medium_confidence,
                'low_confidence': low_confidence,
                'quality_score': (high_confidence * 3 + medium_confidence * 2 + low_confidence) / len(results) if results else 0
            }
        }
        
        return analysis

    def save_comprehensive_results(self, results: List[Dict], analysis: Dict) -> tuple:
        """Save comprehensive results with analysis"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # CSV file
        csv_filename = f"ultimate_startup_discovery_{timestamp}.csv"
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['url', 'source', 'confidence', 'category', 'country', 'method']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for result in results:
                writer.writerow({
                    'url': result['url'],
                    'source': result.get('source', ''),
                    'confidence': result.get('confidence', 0),
                    'category': result.get('category', ''),
                    'country': result.get('country', ''),
                    'method': result.get('method', '')
                })
        
        # JSON file with analysis
        json_filename = f"ultimate_startup_discovery_{timestamp}.json"
        comprehensive_data = {
            'discovery_timestamp': timestamp,
            'total_urls_discovered': len(results),
            'analysis': analysis,
            'urls': results
        }
        
        with open(json_filename, 'w', encoding='utf-8') as jsonfile:
            json.dump(comprehensive_data, jsonfile, indent=2, ensure_ascii=False)
        
        # Summary report
        report_filename = f"discovery_report_{timestamp}.txt"
        with open(report_filename, 'w', encoding='utf-8') as report:
            report.write("üöÄ ULTIMATE STARTUP DISCOVERY REPORT\n")
            report.write("=" * 60 + "\n\n")
            report.write(f"Discovery Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            report.write(f"Total URLs Discovered: {len(results)}\n\n")
            
            report.write("üìä DISCOVERY METHODS:\n")
            for method, count in analysis['method_counts'].items():
                report.write(f"  ‚Ä¢ {method}: {count} URLs\n")
            
            report.write(f"\nüéØ QUALITY METRICS:\n")
            report.write(f"  ‚Ä¢ High Confidence (8-10): {analysis['quality_metrics']['high_confidence']} URLs\n")
            report.write(f"  ‚Ä¢ Medium Confidence (5-7): {analysis['quality_metrics']['medium_confidence']} URLs\n")
            report.write(f"  ‚Ä¢ Low Confidence (1-4): {analysis['quality_metrics']['low_confidence']} URLs\n")
            report.write(f"  ‚Ä¢ Overall Quality Score: {analysis['quality_metrics']['quality_score']:.2f}/3.0\n")
            
            report.write(f"\nüè∑Ô∏è CATEGORIES:\n")
            for category, count in analysis['category_counts'].items():
                report.write(f"  ‚Ä¢ {category}: {count} URLs\n")
            
            report.write(f"\nüåç GEOGRAPHIC DISTRIBUTION:\n")
            for country, count in analysis['country_counts'].items():
                report.write(f"  ‚Ä¢ {country}: {count} URLs\n")
            
            report.write(f"\nüîù TOP 20 HIGHEST CONFIDENCE URLs:\n")
            top_urls = sorted(results, key=lambda x: x.get('confidence', 0), reverse=True)[:20]
            for i, url_data in enumerate(top_urls, 1):
                report.write(f"  {i:2d}. {url_data['url']} (confidence: {url_data.get('confidence', 0)})\n")
        
        return csv_filename, json_filename, report_filename

    def run_ultimate_discovery(self) -> Dict:
        """Run the complete ultimate discovery process"""
        print("üöÄ ULTIMATE STARTUP DISCOVERY SYSTEM")
        print("=" * 60)
        print("üéØ Comprehensive discovery of digital health startups")
        print("üåç Focus: Germany and Europe")
        print("üÜì Using only free tools and methods")
        print("")
        
        start_time = time.time()
        all_results = []
        
        # 1. User hardcoded URLs (highest priority)
        print("1Ô∏è‚É£ USER VERIFIED URLs")
        user_results = self.get_user_hardcoded_urls()
        all_results.extend(user_results)
        
        # 2. Enhanced discovery
        print("\n2Ô∏è‚É£ ENHANCED DISCOVERY")
        enhanced_results = self.run_enhanced_discovery()
        all_results.extend(enhanced_results)
        
        # 3. Google search discovery
        print("\n3Ô∏è‚É£ GOOGLE SEARCH DISCOVERY")
        google_results = self.run_google_search_discovery()
        all_results.extend(google_results)
        
        # 4. Curated startup URLs
        print("\n4Ô∏è‚É£ CURATED STARTUP URLs")
        curated_results = self.add_curated_startup_urls()
        all_results.extend(curated_results)
        
        # 5. Consolidate and rank
        print("\n5Ô∏è‚É£ CONSOLIDATION & RANKING")
        final_results = self.consolidate_and_rank_results(all_results)
        
        # 6. Analyze results
        print("\n6Ô∏è‚É£ ANALYSIS")
        analysis = self.analyze_discovery_results(final_results)
        
        # 7. Save results
        print("\n7Ô∏è‚É£ SAVING RESULTS")
        csv_file, json_file, report_file = self.save_comprehensive_results(final_results, analysis)
        
        end_time = time.time()
        
        # Final summary
        print("\n" + "=" * 60)
        print("üéâ ULTIMATE DISCOVERY COMPLETED!")
        print("=" * 60)
        print(f"‚è±Ô∏è  Total time: {end_time - start_time:.1f} seconds")
        print(f"üìä Total URLs discovered: {len(final_results)}")
        print(f"üéØ Quality score: {analysis['quality_metrics']['quality_score']:.2f}/3.0")
        print(f"üìÅ Files created:")
        print(f"  ‚Ä¢ CSV: {csv_file}")
        print(f"  ‚Ä¢ JSON: {json_file}")
        print(f"  ‚Ä¢ Report: {report_file}")
        
        print(f"\nüîù Top 10 Discovered URLs:")
        for i, url_data in enumerate(final_results[:10], 1):
            print(f"  {i:2d}. {url_data['url']} ({url_data.get('method', 'Unknown')}, confidence: {url_data.get('confidence', 0)})")
        
        print(f"\nüìä Discovery Summary:")
        for method, count in analysis['method_counts'].items():
            print(f"  ‚Ä¢ {method}: {count} URLs")
        
        return {
            'total_urls': len(final_results),
            'results': final_results,
            'analysis': analysis,
            'files': {
                'csv': csv_file,
                'json': json_file,
                'report': report_file
            }
        }

def main():
    """Main function"""
    print("üöÄ ULTIMATE STARTUP DISCOVERY SYSTEM")
    print("=" * 60)
    print("This system combines multiple discovery methods to find")
    print("digital health startup URLs across Germany and Europe.")
    print("")
    print("‚è±Ô∏è  Estimated time: 5-10 minutes")
    print("üÜì Uses only free tools and methods")
    print("")
    
    try:
        # Initialize and run discovery
        discovery = UltimateStartupDiscovery()
        results = discovery.run_ultimate_discovery()
        
        print(f"\n‚ú® SUCCESS! Discovered {results['total_urls']} startup URLs")
        print(f"üìã Next steps:")
        print(f"  1. Review the discovery report: {results['files']['report']}")
        print(f"  2. Use existing part2_url_evaluator.py to test URLs")
        print(f"  3. Use existing part3_company_name_extractor.py to extract company names")
        print(f"  4. Build final startup directory")
        
        return results
        
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è Discovery interrupted by user")
        return None
    except Exception as e:
        print(f"\n‚ùå Error during discovery: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = main()
    if results:
        print(f"\nüéä Ultimate discovery completed successfully!")
    else:
        print(f"\n‚ö†Ô∏è Discovery completed with issues")